{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPQ/ZH+K9yTtW0LrAK+kN++",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fbeilstein/dbms/blob/master/db_lecture_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Failure Detection**\n",
        "\n",
        "Failures should be detected in a timely manner. A faulty process might get contacted even though it won’t be able to respond, increasing latencies and reducing overall system availability.\n",
        "\n",
        "Detecting failures in asynchronous distributed systems (i.e., without making any timing assumptions) is extremely difficult as it’s impossible to tell whether the process has crashed, or is running slowly and taking an indefinitely long time to respond (FLP impossibility, previous lecture). \n",
        "\n",
        "* process that has stopped executing its steps completely: dead, failed or crashed\n",
        "* suspected process (may be dead): unresponsive, faulty, slow\n",
        "\n",
        "Failures may occur \n",
        "* link level (messages between processes are lost or delivered slowly)\n",
        "* process level (the process crashes or is running slowly)\n",
        "\n",
        "\n",
        "Slowness may not always be distinguishable from failure = trade-off between wrongly suspecting alive processes as dead and delaying marking an unresponsive process as dead.\n",
        "\n",
        "A **failure detector** is a local subsystem responsible for identifying failed or unreachable processes to exclude them from the algorithm and guarantee liveness while preserving safety.\n",
        "\n",
        "**Liveness** and **safety** are the properties that describe an algorithm’s ability to solve a specific problem and the correctness of its output. \n",
        "\n",
        "* **liveness** guarantees that a specific intended event must occur (e.g. process failed -> failure detected).\n",
        "* **safety** guarantees that unintended events will not occur (e.g. considered dead -> really dead). \n",
        "\n",
        "We want from failure detector **efficiency** (detect fails fast) and **accuracy** (detect fails precise). We can think of the relationship between efficiency and accuracy as a tunable parameter: a more efficient algorithm might be less precise, and a more accurate algorithm is usually less efficient. \n",
        "\n",
        "\n",
        "Often failure detectors are allowed to produce false-positives and assume the **absence of Byzantine failures** (processes do not attempt to intentionally lie about their state)\n",
        "\n",
        "Failure detectors are an essential prerequisite and an integral part of many consensus and atomic broadcast algorithms."
      ],
      "metadata": {
        "id": "Ed5Pgo1QvY_Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Heartbeats and Pings**\n",
        "\n",
        "We can query the state of remote processes by\n",
        "* **ping**, which sends messages to remote processes, checking if they are still alive by expecting a response within a specified time period.\n",
        "* **heartbeat** when the process is actively notifying its peers that it’s\n",
        "still running by sending messages to them.\n",
        "\n",
        "Each process maintains a list of other processes (alive, dead, and suspected ones) and updates it with the last response time for each process. If a process fails to respond to a ping message or produce heartbeat for a longer time, it is marked as suspected.\n",
        "\n",
        "Many failure-detection algorithms are based on heartbeats and timeouts. For example, [Akka](https://akka.io/), a popular framework for building distributed systems, has an implementation of a deadline failure detector, which uses heartbeats.\n",
        "\n",
        "This approach has several potential downsides: \n",
        "* precision relies on the careful selection of ping frequency and timeout\n",
        "* does not capture process visibility from the perspective of other processes"
      ],
      "metadata": {
        "id": "HQUD23RLzqMG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Timeout-Free Failure Detector**\n",
        "\n",
        "Some algorithms avoid relying on timeouts for detecting failures. For example [Aguilera, Marcos K., Wei Chen, and Sam Toueg. **1997**. “Heartbeat: a Timeout-Free Failure Detector for Quiescent Reliable Communication.”](https://www.microsoft.com/en-us/research/uploads/prod/1997/09/wdag97_hb.pdf)\n",
        "\n",
        "Assumptions:\n",
        "* any two correct processes are connected to each other with a fair path, which contains only fair links (i.e., if a message is sent over this link infinitely often, it is also received infinitely often)\n",
        "* each process is aware of the existence of all other processes in the network.\n",
        "\n",
        "\n",
        "Each process maintains a list of neighbors and counters associated with them. \n",
        "1. Send initial message (contains the first sender in the path and a unique identifier that can be used to avoid broadcasting the same message multiple times)\n",
        "2. If new message received:\n",
        "  - append itself to the path\n",
        "  - send the heartbeat to the ones that are not present there (note: propagation stops if all known processes received it)\n",
        "  - increments counters for all participants present in the path (note: OK processes have unbounded heartbeats, fault -- bounded)\n",
        " \n",
        "Since messages are propagated through different processes, and heartbeat paths contain aggregated information received from the neighbors, we can (correctly) mark an unreachable process as alive even when the direct link between the two processes is faulty.\n",
        "\n",
        "Heartbeat counters represent a global and normalized view of the system. This view captures how the heartbeats are propagated relative to one another, allowing us to compare processes. However, one of the shortcomings of this approach is that interpreting heartbeat counters may be quite tricky: we need to pick a threshold that can yield reliable results. Unless we can do that, the algorithm will falsely mark active processes as suspected."
      ],
      "metadata": {
        "id": "y2SEvSQXiTMM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Outsourced Heartbeats**\n",
        "\n",
        "\n",
        "An alternative approach, used by the [Scalable Weakly Consistent Infection-style Process Group Membership Protocol (SWIM)](https://dl.acm.org/doi/pdf/10.1145/3361525.3361556) is to use outsourced heartbeats to **improve reliability** using information about the process liveness from the\n",
        "perspective of its neighbors. \n",
        "\n",
        "\n",
        "This approach does not require processes to be aware of all other processes in the network, only a subset of connected peers.\n",
        "\n",
        "Suppose P1,P2,P3 neighbours of PB\n",
        "\n",
        "P1 -ping-> PB. If alive mark as ok. If not: P1 -message-> P2,P3 -ping-> PB. If alive P2,P3 -message-> P1.  \n",
        "\n",
        "This allows accounting for both direct and indirect reachability, we can check the state of PB from the perspective of P1,P2,P3.\n",
        "\n",
        "Outsourced heartbeats allow reliable failure detection by distributing responsibility for deciding across the group of members. \n",
        "* does not require broadcasting messages to a broad group of peers (choose few randomly). \n",
        "* can be triggered in parallel\n",
        "* allow us to make more accurate decisions."
      ],
      "metadata": {
        "id": "yP5EaCCuoRtw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Phi-Accrual Failure Detector**\n",
        "\n",
        "Used in many distributed systems, e.g. **Cassandra** and **Akka** (along with the aforementioned deadline failure detector).\n",
        "\n",
        "Instead of treating node failure as a binary problem, where the process can be only in two states: up or down, a [phi-accrual (φ-accrual) failure detector](https://oneofus.la/have-emacs-will-hack/files/HDY04.pdf) has a continuous scale, capturing the probability of the monitored process’s crash. \n",
        "\n",
        "It works by maintaining a sliding window, collecting arrival times of the most recent heartbeats from the peer processes. This information is used to approximate arrival time of the next heartbeat, compare this approximation with the actual arrival time, and compute the suspicion level φ: how certain the failure detector is about the failure, given the current network conditions. If this value reaches a threshold, the node is marked as down.\n",
        "\n",
        "This failure detector dynamically adapts to changing network conditions by adjusting the scale on which the node can be marked as a suspect. \n",
        "\n",
        "From the architecture perspective, a phi-accrual failure detector can be viewed as a combination of three subsystems:\n",
        "* **Monitoring**\n",
        "Collecting liveness information through pings, heartbeats, or request-response\n",
        "sampling.\n",
        "* **Interpretation**\n",
        "Making a decision on whether or not the process should be marked as suspected.\n",
        "* **Action**\n",
        "A callback executed whenever the process is marked as suspected. \n",
        "\n",
        "\n",
        "The monitoring process collects and stores data samples (which are assumed to follow a normal distribution) in a fixed-size window of heartbeat arrival times. Newer arrivals are added to the window, and the oldest heartbeat data points are discarded. Distribution parameters are estimated from the sampling window by determining the **mean** and **variance** of samples. This information is used to compute the probability of arrival of the message within t time units after the previous one. Given this information, we compute φ, which describes how likely we are to make a correct decision about a process’s liveness. In other words, how likely it is to make a mistake and receive a heartbeat that will contradict the calculated assumptions.\n",
        "\n"
      ],
      "metadata": {
        "id": "BzXA1LWgsYkV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gossip and Failure Detection**\n",
        "\n",
        "Another approach that avoids relying on a single-node view to make a decision is a gossip-style failure detection service (van Renesse, Robbert, Yaron Minsky, and Mark Hayden. 1998. “A Gossip-Style Failure Detection Service.”), which uses gossip (analogy: think about virus spreading) to collect and distribute states of neighboring processes.\n",
        "\n",
        "* Each process maintains table\n",
        "\n",
        "Neighbour | Last Heartbeat timestamp\n",
        "---|---\n",
        "P1 (self) | t1\n",
        "P2 | t2\n",
        "P3 | t3\n",
        "\n",
        "* Periodically, each member increments its heartbeat counter and distributes its list to a random neighbor. \n",
        "\n",
        "* Upon the message receipt, the neighboring node merges the list with its own, updating heartbeat counters for the other neighbors.\n",
        "\n",
        "* If any node did not update its counter for long enough, it is considered failed. \n",
        "\n",
        "Failure timeout and communication frequency should be carefully chosen.\n",
        "\n",
        "Note: bandwidth is capped, and can grow at most linearly with a number of processes in the system.\n",
        "\n",
        "\n",
        "Case study: consider 3 processes P1,P2,P3.\n",
        "* All three can communicate and update their timestamps.\n",
        "* Link P1-P3 is lost. Its state is still propagated through P2.\n",
        "* P3 crashes. Since it doesn’t send updates anymore, it is detected as failed by\n",
        "other processes.\n",
        "\n",
        "This way, we can detect crashed nodes, as well as the nodes that are unreachable by any other cluster member. This decision is reliable, since the view of the cluster is an aggregate from multiple nodes. If there’s a link failure between the two hosts, heartbeats can still propagate through other processes. Using gossip for propagating system states increases the number of messages in the system, but allows information to spread more reliably"
      ],
      "metadata": {
        "id": "g5K5hWpQvok2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reversing Failure Detection Problem** \n",
        "\n",
        "Since propagating the information about failures is not always possible, and propagating it by notifying every member might be expensive, one of the approaches, called [FUSE (failure notification service)](https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.59.2061), focuses on reliable and cheap\n",
        "failure propagation that works even in cases of network partitions.\n",
        "\n",
        "\n",
        "This approach arranges all active processes in groups. Every time a single process failure is detected, it is converted and propagated as a group failure. This allows detecting failures in the presence of any pattern of disconnects, partitions, and node failures.\n",
        "\n",
        "* send pings to members of group\n",
        "* if anyone did not respond - stop responding as well\n",
        "\n",
        "\n",
        "All failures are propagated through the system from the source of failure to all other participants. Participants gradually stop responding to pings, converting from the individual node failure to the group failure.\n",
        "\n",
        "(+) every member is guaranteed to learn about group failure and adequately react to it. \n",
        "\n",
        "\n",
        "(-) link failure separating a single process from other ones can be converted to the group failure as well"
      ],
      "metadata": {
        "id": "kucmmuoq4IJe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Leader Election**\n",
        "\n",
        "* Synchronization can be quite costly: if each algorithm step involves contacting each other participant, we can end up with a significant communication overhead. This is particularly true in large and geographically distributed networks. \n",
        "* Some algorithms rely on the existence of the leader (sometimes called coordinator) process, responsible for executing or coordinating steps of a distributed algorithm.\n",
        "\n",
        "\n",
        "Usually, the process remains a leader until it crashes. After the crash, any other process can start a new election round, assume leadership, if it gets elected, and continue the failed leader’s work.\n",
        "\n",
        "\n",
        "We expect\n",
        "* **liveness** of the election algorithm (guarantees that most of the time there will be a leader, and the election will eventually complete)\n",
        "* **safety** - guarantee there may be at most one leader at a time, and completely eliminate the possibility of a **split brain** situation (when two\n",
        "leaders serving the same purpose are elected but unaware of each other). \n",
        "\n",
        "Leader processes can: order messages and disseminate them among the processes, coordinate system reorganization after the failure, during initialization, or when important state changes happen.\n",
        "\n",
        "\n",
        "Having a stable leader in the system helps to avoid state synchronization between remote participants, reduce the number of exchanged messages, and drive execution from a single process instead of requiring peer-to-peer coordination. \n",
        "\n",
        "\n",
        "One of the potential **problems** in systems with a notion of leadership is that the leader can become a bottleneck. To overcome that, many systems partition data in nonintersecting independent replica sets (partitioning).\n",
        "Instead of having a single system-wide leader, each replica set has its own leader. One of the systems that uses this approach is [Spanner](https://en.wikipedia.org/wiki/Spanner_(database))."
      ],
      "metadata": {
        "id": "zgHOMdfBp7Xo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bully Algorithm**\n",
        "\n",
        "[See \"Elections in a Distributed Computing System\" for few variants](http://vis.usal.es/rodrigo/documentos/papers/BullyAlgorithm.pdf)\n",
        "\n",
        "* Each process gets a unique rank assigned to it. \n",
        "* During the election, the process with the highest rank becomes a leader.\n",
        "\n",
        "This algorithm is known for its simplicity. The algorithm is named bully because the highest-ranked node “bullies” other nodes into accepting it. It is also known as monarchial leader election: the highest-ranked sibling becomes a monarch after the previous one ceases to exist.\n",
        "\n",
        "\n",
        "\n",
        "1. The process sends election messages to processes with higher identifiers.\n",
        "2. The process waits, allowing higher-ranked processes to respond. If no higher-ranked process responds, it proceeds with step 3. Otherwise, the process notifies the highest-ranked process it has heard from, and allows it to proceed with step 3.\n",
        "3. The process assumes that there are no active processes with a higher rank, and notifies all lower-ranked processes about the new leader.\n",
        "\n",
        "\n",
        "Consider processes with ranks 1,2,3,4,5,6. Initial leader was 6. 6 crashes. Look, for example, process 3. 3 -ping-> 4,5,6. 4,5-alive-> 3. 3 -notify-> 5. 5 -notify-> 1,2,3,4.\n",
        "\n",
        "**downsides**\n",
        "* violates the safety guarantee in the presence of network partitions (2 components elect 2 leaders). This situation is called **split brain**.\n",
        "* An unstable high-ranked node proposes itself as a leader, fails shortly\n",
        "thereafter, wins reelection, fails again, and the whole process repeats. This problem can be solved by distributing host quality metrics and taking them into consideration during the election."
      ],
      "metadata": {
        "id": "Cz464Pv0sqN4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Next-In-Line Failover**\n",
        "\n",
        "There are many versions of the bully algorithm that improve its various properties. For example, we can use multiple next-in-line alternative processes as a failover to shorten reelections.\n",
        "\n",
        "* Each elected leader provides a list of failover nodes. \n",
        "* When one of the processes detects a leader failure, it starts a new election round by sending a message to the highest-ranked alternative from the list provided by the failed leader. \n",
        "* If one of the proposed alternatives is up, it becomes a new leader without having to go through the complete election round. \n",
        "* If the process that has detected the leader failure is itself the highest ranked process from the list, it can notify the processes about the new leader right away.\n",
        "\n",
        "Consider processes with ranks 1,2,3,4,5,6. Initial leader was 6, it provides alternative 5. 6 crashes. Look, for example, process 3. 3 -ping-> 5. 5-alive-> 3. 3 -notify-> 5. 5 -notify-> 1,2,3,4.\n",
        "\n",
        "As a result, we require fewer steps during the election if the next-in-line process is alive"
      ],
      "metadata": {
        "id": "ze-LrtKDAqSa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Candidate/Ordinary Optimization**\n",
        "\n",
        "\n",
        "Another algorithm attempts to lower requirements on the number of messages by\n",
        "splitting the nodes into two subsets, candidate and ordinary, where only one of the candidate nodes can eventually become a leader.\n",
        "\n",
        "\n",
        "The ordinary process initiates election by contacting candidate nodes, collecting responses from them, picking the highest-ranked alive candidate as a new leader, and then notifying the rest of the nodes about the election results.\n",
        "\n",
        "\n",
        "To solve the problem with multiple simultaneous elections, the algorithm proposes to use a tiebreaker variable δ, a process-specific delay, varying significantly between the nodes, that allows one of the nodes to initiate the election before the other ones. The tiebreaker time is generally greater than the message round-trip time. Nodes with higher priorities have a lower δ, and vice versa.\n",
        "\n",
        "\n",
        "Consider processes with ranks 1,2,3,4,5,6. Initial leader was 6, candidates = 1,2,6, ordinary=3,4,5. 6 crashes. Look, for example, process 3. 3 -ping-> 1,2. 1,2-alive-> 3. 2 new leader. 3 -notify-> 1,2,4,5.\n"
      ],
      "metadata": {
        "id": "CS7XpRxsRbSO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Invitation Algorithm**\n",
        "\n",
        "\n",
        "An invitation algorithm allows processes to “invite” other processes to join their groups instead of trying to outrank them. \n",
        "\n",
        "This algorithm allows multiple leaders by definition, since each group has its own leader.\n",
        "\n",
        "Each process starts as a leader of a new group, where the only member is the process itself. Group leaders contact peers that do not belong to their groups, inviting them to join. If the peer process is a leader itself, two groups are merged. Otherwise, the contacted process responds with a group leader ID, allowing two group leaders to establish contact and merge groups in fewer steps.\n",
        "\n",
        "If peer gets 2 or more invitation it may accept any (groups will grow and merge into one at the end).\n",
        "\n",
        "Since groups are merged, it doesn’t matter whether the process that suggested the group merge becomes a new leader or the other one does. To keep the number of messages required to merge groups to a minimum, a leader of a larger group can become a leader for a new group. This way only the processes from the smaller group have to be notified about the change of leader.\n",
        "\n",
        "\n",
        "Similar to the other discussed algorithms, this algorithm allows processes to settle in multiple groups and have multiple leaders. The invitation algorithm allows creating process groups and merging them without having to trigger a new election from scratch, reducing the number of messages required to finish the election."
      ],
      "metadata": {
        "id": "dicgWBCYVq77"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ring Algorithm**\n",
        "\n",
        "\n",
        "In the [ring algorithm](https://dl.acm.org/doi/pdf/10.1145/359104.359108), all nodes in the system form a ring and are aware of the ring topology (i.e., their predecessors and successors in the ring). \n",
        "\n",
        "When the process detects the leader failure, it starts the new election. The election message is forwarded across the ring: each process contacts its successor (the next node closest to it in the ring). If this node is unavailable, the process skips the unreachable node and attempts to contact the nodes after it in the ring, until eventually one of them responds. Nodes contact their siblings, following around the ring and collecting the live node\n",
        "set, adding themselves to the set before passing it over to the next node, similar to the failure-detection algorithm described in “Timeout-Free Failure Detector”, where nodes append their identifiers to the path before passing it to the next node.\n",
        "\n",
        "The algorithm proceeds by fully traversing the ring. When the message comes back to the node that started the election, the highest-ranked node from the live set is chosen as a leader. \n",
        "\n",
        "Consider processes 1,2,3,4,5,6. 6 - leader. 6 crashes. Let 3 start election.\n",
        "\n",
        "3 -ping,{3}-> 4\n",
        "\n",
        "4 -ping,{3,4}-> 5\n",
        "\n",
        "5 -ping,{3,4,5}-> 6, 6 dead\n",
        "\n",
        "5 -ping,{3,4,5}-> 1\n",
        "\n",
        "1 -ping,{3,4,5,1}-> 2\n",
        "\n",
        "2 -ping,{3,4,5,1,2}-> 3\n",
        "\n",
        "3 -notify,{new leader 5}-> 4\n",
        "\n",
        "...\n",
        "\n",
        "etc \n",
        "\n",
        "\n",
        "Variants of this algorithm include collecting a single highest-ranked identifier instead of a set of active nodes to save space. When the algorithm comes back to the node that has started the election, the last known highest identifier is circulated across the ring once again.\n",
        "\n",
        "\n",
        "Since the ring can be partitioned in two or more parts, with each part potentially electing its own leader, this approach **doesn’t hold a safety property**."
      ],
      "metadata": {
        "id": "egDMhXjxwyqt"
      }
    }
  ]
}
